{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"niVq6bRaqNWc","outputId":"d8ccfcf4-f74b-4557-dde6-40aa1e1e4867"},"outputs":[{"ename":"error","evalue":"OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-inblc7p7\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[1;32m<ipython-input-1-f9ff0858bcbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Read Map Image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mfmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2D_field.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mfmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1050\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m680\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# 9 correspondences for perspective transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31merror\u001b[0m: OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-inblc7p7\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"]}],"source":["import numpy as np\n","import cv2 \n","\n","# create videocapture\n","cap = cv2.VideoCapture('output.mp4')\n","\n","# create Background Subtractor objects\n","backSub = cv2.createBackgroundSubtractorKNN()\n","\n","# Read Map Image\n","fmap = cv2.imread('2D_field.png')\n","fmap = cv2.resize(fmap,(1050,680))\n","\n","# 9 correspondences for perspective transform\n","points1 = np.array([(144,166),\n","                    (1136,116),\n","                    (873,780),\n","                    (639,110),\n","                    (673,200),\n","                    (490,210),\n","                    (857,192),\n","                    (660,162),\n","                    (692,251)], dtype=np.int32)\n","\n","points2 = np.array([(164,147),\n","                    (886,147),\n","                    (525,676),\n","                    (525,4),\n","                    (525,340),\n","                    (430,340),\n","                    (618,340),\n","                    (525,250),\n","                    (525,430)],   dtype=np.int32)   \n","\n","# find perspective transform\n","H, _ = cv2.findHomography(points1, points2, cv2.RANSAC,5.0)\n","\n","u=0 \n","# b=-1\n","\n","while True:\n","#     b+=1\n","#     if b%400==0:\n","    \n","        u += 1\n","        # read video frame by frame\n","        ret, frame = cap.read()\n","\n","        if ret == False:\n","            break\n","\n","\n","\n","        # apply GaussianBlur \n","        m = 5\n","        frame2 = cv2.GaussianBlur(frame,(m,m),0)\n","#         cv2.line(frame2,(0,120),(1280,57),color=(0,0,0),thickness=40)\n","\n","        # update the background model (get foreground mask)\n","        fgMask = backSub.apply(frame2)\n","\n","        # threshold for removing shadows\n","        ret, fgMask = cv2.threshold(fgMask,128,255,cv2.THRESH_BINARY)\n","\n","        # opening\n","        # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,15))\n","\n","        kernel = np.array([[0,0,0,1,1,0,0,0],\n","                            [0,0,0,1,1,0,0,0],\n","                            [0,1,1,1,1,1,1,0],\n","                            [0,1,1,1,1,1,1,0],\n","                            [0,1,1,1,1,1,1,0],\n","                            [0,1,1,1,1,1,1,0],\n","                            [0,0,1,1,1,1,0,0],\n","                            [0,0,1,1,1,1,0,0],\n","                            [0,0,1,1,1,1,0,0]], dtype='uint8')\n","\n","        fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)\n","\n","\n","        #closing\n","        kernel = np.array([ [0,0,0,1,1,0,0,0],\n","                            [0,0,0,1,1,0,0,0],\n","                            [0,1,1,1,1,1,1,0],\n","                            [0,1,1,1,1,1,1,0],\n","                            [0,1,1,1,1,1,1,0],\n","                            [0,1,1,1,1,1,1,0],\n","                            [0,1,1,1,1,1,1,0],\n","                            [0,1,1,1,1,1,1,0],\n","                            [0,0,1,1,1,1,0,0],\n","                            [0,0,1,1,1,1,0,0],\n","                            [0,0,1,1,1,1,0,0]], dtype='uint8')\n","\n","        fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)\n","\n","        n,C,stats, centroids = cv2.connectedComponentsWithStats(fgMask);\n","\n","        f = fmap.copy()\n","\n","\n","        for i in range(1,n):\n","\n","            if stats[i,cv2.CC_STAT_TOP]<=240:\n","                if stats[i,cv2.CC_STAT_AREA]>20:\n","                    point = centroids[i].reshape(-1,1,2).astype(np.float32)\n","                    dst2 = cv2.perspectiveTransform(point,H).reshape(1,2)\n","                    dst2 = dst2.astype('int32')\n","                    cv2.circle(f,(dst2[0,0], dst2[0,1]), radius=7, color=[0,0,255], thickness=-1)\n","#                     box = frame[stats[i,1]:stats[i,1]+stats[i,3],stats[i,0]:stats[i,0]+stats[i,2]]\n","#                     box = cv2.resize(box,(45,45))\n","#                     filename = str(u)+str(i)+'.jpg'\n","#                     cv2.imwrite(filename,box)\n","\n","\n","            elif 240<stats[i,cv2.CC_STAT_TOP]<=480:\n","                if stats[i,cv2.CC_STAT_AREA]>400:\n","                    point = centroids[i].reshape(-1,1,2).astype(np.float32)\n","                    dst2 = cv2.perspectiveTransform(point,H).reshape(1,2)\n","                    dst2 = dst2.astype('int32')\n","                    cv2.circle(f,(dst2[0,0], dst2[0,1]), radius=7, color=[0,0,255], thickness=-1)\n","#                     box = frame[stats[i,1]:stats[i,1]+stats[i,3],stats[i,0]:stats[i,0]+stats[i,2]]\n","#                     box = cv2.resize(box,(45,45))\n","#                     filename = str(u)+str(i)+'.jpg'\n","#                     cv2.imwrite(filename,box)\n","\n","            elif 480<stats[i,cv2.CC_STAT_TOP]:\n","                if stats[i,cv2.CC_STAT_AREA]>1600:\n","                    point = centroids[i].reshape(-1,1,2).astype(np.float32)\n","                    dst2 = cv2.perspectiveTransform(point,H).reshape(1,2)\n","                    dst2 = dst2.astype('int32')\n","                    cv2.circle(f,(dst2[0,0], dst2[0,1]), radius=7, color=[0,0,255], thickness=-1)\n","#                     box = frame[stats[i,1]:stats[i,1]+stats[i,3],stats[i,0]:stats[i,0]+stats[i,2]]\n","#                     box = cv2.resize(box,(45,45))\n","#                     filename = str(u)+str(i)+'.jpg'\n","#                     cv2.imwrite(filename,box)\n","\n","        #r = cv2.selectROI(\"Image\", frame)\n","        #imCrop = frame[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n","        # show the current frame ,the fg masks and Map\n","            cv2.imshow('Frame', frame)\n","            cv2.imshow('FG Mask', fgMask)\n","        #cv2.imshow('Map', imCrop)\n","\n","            if cv2.waitKey(1) == ord('q'):\n","                break\n","\n","cap.release()\n","cv2.destroyAllWindows()    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSq7NXT9qNWn","outputId":"414125b7-9ab7-44c8-9b5a-810ae960e83e"},"outputs":[{"data":{"text/plain":["5756000"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y295DPa6qNWo","outputId":"50b19b97-2221-44a6-94d7-e4519bdd7267"},"outputs":[{"ename":"error","evalue":"OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-inblc7p7\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[1;32m<ipython-input-3-0dfed991d118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Read Map Image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mfmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2D_field.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mfmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1050\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m680\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# 9 correspondences for perspective transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31merror\u001b[0m: OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-inblc7p7\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"]}],"source":["import numpy as np\n","import cv2 \n","\n","# create videocapture\n","cap = cv2.VideoCapture('output.mp4')\n","\n","# create Background Subtractor objects\n","backSub = cv2.createBackgroundSubtractorKNN()\n","\n","# Read Map Image\n","fmap = cv2.imread('2D_field.png')\n","fmap = cv2.resize(fmap,(1050,680))\n","\n","# 9 correspondences for perspective transform\n","points1 = np.array([(144,166),\n","                    (1136,116),\n","                    (873,780),\n","                    (639,110),\n","                    (673,200),\n","                    (490,210),\n","                    (857,192),\n","                    (660,162),\n","                    (692,251)], dtype=np.int32)\n","\n","points2 = np.array([(164,147),\n","                    (886,147),\n","                    (525,676),\n","                    (525,4),\n","                    (525,340),\n","                    (430,340),\n","                    (618,340),\n","                    (525,250),\n","                    (525,430)],   dtype=np.int32)   \n","\n","# find perspective transform\n","H, _ = cv2.findHomography(points1, points2, cv2.RANSAC,5.0)\n","\n","u=0 \n","\n","while True:\n","    \n","    u += 1\n","    # read video frame by frame\n","    ret, frame = cap.read()\n","    \n","    if ret == False:\n","        break\n","    \n","    \n","    \n","    # apply GaussianBlur \n","    m = 5\n","    frame2 = cv2.GaussianBlur(frame,(m,m),0)\n","    cv2.line(frame2,(0,120),(1280,57),color=(0,0,0),thickness=40)\n","\n","    # update the background model (get foreground mask)\n","    fgMask = backSub.apply(frame2)\n","    \n","    # threshold for removing shadows\n","    ret, fgMask = cv2.threshold(fgMask,128,255,cv2.THRESH_BINARY)\n","    \n","    # opening\n","    # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,15))\n","    \n","    kernel = np.array([[0,0,0,1,1,0,0,0],\n","                        [0,0,0,1,1,0,0,0],\n","                        [0,1,1,1,1,1,1,0],\n","                        [0,1,1,1,1,1,1,0],\n","                        [0,1,1,1,1,1,1,0],\n","                        [0,1,1,1,1,1,1,0],\n","                        [0,0,1,1,1,1,0,0],\n","                        [0,0,1,1,1,1,0,0],\n","                        [0,0,1,1,1,1,0,0]], dtype='uint8')\n","    \n","    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)\n","    \n","    \n","    #closing\n","    kernel = np.array([ [0,0,0,1,1,0,0,0],\n","                        [0,0,0,1,1,0,0,0],\n","                        [0,1,1,1,1,1,1,0],\n","                        [0,1,1,1,1,1,1,0],\n","                        [0,1,1,1,1,1,1,0],\n","                        [0,1,1,1,1,1,1,0],\n","                        [0,1,1,1,1,1,1,0],\n","                        [0,1,1,1,1,1,1,0],\n","                        [0,0,1,1,1,1,0,0],\n","                        [0,0,1,1,1,1,0,0],\n","                        [0,0,1,1,1,1,0,0]], dtype='uint8')\n","    \n","    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)\n","    \n","    n,C,stats, centroids = cv2.connectedComponentsWithStats(fgMask);\n","    \n","    f = fmap.copy()\n","\n","   \n","    for i in range(1,n):\n","    \n","        if stats[i,cv2.CC_STAT_TOP]<=240:\n","            if stats[i,cv2.CC_STAT_AREA]>20:\n","                point = centroids[i].reshape(-1,1,2).astype(np.float32)\n","                dst2 = cv2.perspectiveTransform(point,H).reshape(1,2)\n","                dst2 = dst2.astype('int32')\n","                cv2.circle(f,(dst2[0,0], dst2[0,1]), radius=7, color=[0,0,255], thickness=-1)\n","                box = frame[stats[i,1]:stats[i,1]+stats[i,3],stats[i,0]:stats[i,0]+stats[i,2]]\n","                box = cv2.resize(box,(45,45))\n","                filename = str(u)+str(i)+'.jpg'\n","                cv2.imwrite(filename,box)\n","                \n","                \n","        elif 240<stats[i,cv2.CC_STAT_TOP]<=480:\n","            if stats[i,cv2.CC_STAT_AREA]>400:\n","                point = centroids[i].reshape(-1,1,2).astype(np.float32)\n","                dst2 = cv2.perspectiveTransform(point,H).reshape(1,2)\n","                dst2 = dst2.astype('int32')\n","                cv2.circle(f,(dst2[0,0], dst2[0,1]), radius=7, color=[0,0,255], thickness=-1)\n","                box = frame[stats[i,1]:stats[i,1]+stats[i,3],stats[i,0]:stats[i,0]+stats[i,2]]\n","                box = cv2.resize(box,(45,45))\n","                filename = str(u)+str(i)+'.jpg'\n","                cv2.imwrite(filename,box)\n","                \n","        elif 480<stats[i,cv2.CC_STAT_TOP]:\n","            if stats[i,cv2.CC_STAT_AREA]>1600:\n","                point = centroids[i].reshape(-1,1,2).astype(np.float32)\n","                dst2 = cv2.perspectiveTransform(point,H).reshape(1,2)\n","                dst2 = dst2.astype('int32')\n","                cv2.circle(f,(dst2[0,0], dst2[0,1]), radius=7, color=[0,0,255], thickness=-1)\n","                box = frame[stats[i,1]:stats[i,1]+stats[i,3],stats[i,0]:stats[i,0]+stats[i,2]]\n","                box = cv2.resize(box,(45,45))\n","                filename = str(u)+str(i)+'.jpg'\n","                cv2.imwrite(filename,box)\n","    \n","    #r = cv2.selectROI(\"Image\", frame)\n","    #imCrop = frame[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n","    # show the current frame ,the fg masks and Map\n","    cv2.imshow('Frame', frame)\n","    cv2.imshow('FG Mask', fgMask)\n","    #cv2.imshow('Map', imCrop)\n","\n","    if cv2.waitKey(1) == ord('q'):\n","        break\n","    \n","cap.release()\n","cv2.destroyAllWindows()    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-w3BT3LSqNWr"},"outputs":[],"source":["import cv2 \n","cap = cv2.VideoCapture(0)\n","while 1:\n","    if ret == False:\n","        break\n","    cv2.imshow('Frame', frame)\n","    if cv2.waitKey(1) == ord('q'):\n","        break\n","    \n","ret, frame = cap.read()\n","cap.release()\n","cv2.destroyAllWindows()  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2OMeHbBQqNWs"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}